{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HUFFLEPUFF BUSINESS TRAVEL ANALYSIS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BUSINESS PROBLEM #1\n",
    "- We want our employees to only travel to green countries\n",
    "\n",
    "## HYPOTHESIS \n",
    "- Some countries have lower air travel CO2 emissions per passenger\n",
    "- In some countries the share of CO2 emmissions created from domestic flights surpasses the ones created from international flights\n",
    "- Some countries have lower total CO2 emissions total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Benjamin    : Air travel\n",
    "- Ricardo     : Energy \n",
    "- Anna        : Air pollution \n",
    "- Xinly       : Plasctic pollution \n",
    "- Jp          : Deforastation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO remane owid codes to iso codes\n",
    "#TODO export to sql from python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import pycountry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pycountry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POPULATION CLEANING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import population data\n",
    "populations_df = pd.read_csv('sources/population.csv')\n",
    "\n",
    "def import_csv(filename):\n",
    "    return pd.read_csv('sources/' + filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = {\n",
    "    \"population\": {\n",
    "        \"filename\": \"population.csv\",\n",
    "        \"columns\": {\n",
    "            \"country\": {\"originalName\": \"Entity\", \"type\": \"object\"},\n",
    "            \"population\": {\"originalName\": \"Population - Sex: all - Age: all - Variant: estimates\", \"type\": \"int\"},\n",
    "            \"code\": {\"originalName\": \"Code\", \"type\": \"object\"},\n",
    "            \"year\": {\"originalName\": \"Year\", \"type\": \"int\"},\n",
    "            },\n",
    "    },\n",
    "    \n",
    "    \"deforestation\": {\n",
    "        \"filename\": \"imported-deforestation.csv\",\n",
    "        \"columns\": {\n",
    "            \"country\": {\"originalName\": \"Entity\", \"type\": \"object\"},\n",
    "            \"imported_deforestation\": {\"originalName\": \"imported_deforestation\", \"type\": \"float\"},\n",
    "            \"code\": {\"originalName\": \"ISO_A3\", \"type\": \"object\"},\n",
    "            \"year\": {\"originalName\": \"Year\", \"type\": \"int\"},\n",
    "            },\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#functions\n",
    "def rename_columns(df, new_names_dict):\n",
    "    df = df.rename(columns=new_names)\n",
    "    return df\n",
    "\n",
    "def clean_owid_data(schema)-> pd.DataFrame:\n",
    "    df = import_csv(filename)\n",
    "    df = rename_columns(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns\n",
    "col_names = {'Entity': 'country', 'Code': 'code', 'Year': 'year','Population - Sex: all - Age: all - Variant: estimates': 'population'}\n",
    "populations_df = populations_df.rename(columns=col_names)\n",
    "populations_df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#population by country latest year\n",
    "populations_df_latest = populations_df.loc[populations_df.groupby('country')['year'].idxmax()]\n",
    "populations_df_latest.head()\n",
    "\n",
    "def get_latest_year_data(df, group_column, year_column = 'year'):\n",
    "    df_latest = df.loc[df.groupby('country')['year'].idxmax()]\n",
    "    return df_latest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imported deforestation by country latest year\n",
    "populations_df_latest = populations_df.loc[populations_df.groupby('country')['year'].idxmax()]\n",
    "populations_df_latest.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop nan values\n",
    "populations_df_latest = populations_df_latest.dropna()\n",
    "populations_df_latest.head()\n",
    "\n",
    "def drop_nan_values(df):\n",
    "    df = df.dropna()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export clean population csv\n",
    "populations_df_latest.to_csv('sources/clean/population-clean.csv', index=False)\n",
    "\n",
    "def export_csv(df, file_name):\n",
    "    df.to_csv(file_name, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DEFORESTATION CLEANING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import deforestation data\n",
    "forest_df = pd.read_csv('sources/imported-deforestation.csv')\n",
    "forest_df = forest_df.rename(columns=col_names)\n",
    "forest_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imported deforestation by country latest year\n",
    "forest_df_latest = forest_df.loc[forest_df.groupby('country')['year'].idxmax()]\n",
    "forest_df_latest.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export clean deforestation csv\n",
    "forest_df_latest.to_csv('sources/clean/imported-deforestation-clean.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DEFORESTATION ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deforestation_final = forest_df_latest.merge(populations_df_latest, on='code')\n",
    "deforestation_final['imported_deforestation_per_capita'] = deforestation_final['imported_deforestation'] / deforestation_final['population']\n",
    "\n",
    "min_deforestation = deforestation_final['imported_deforestation_per_capita'].min()\n",
    "max_deforestation = deforestation_final['imported_deforestation_per_capita'].max()\n",
    "\n",
    "deforestation_final['score'] = 1 + 9 * (deforestation_final['imported_deforestation_per_capita'] - min_deforestation) / (max_deforestation - min_deforestation)\n",
    "deforestation_final['score'] = deforestation_final['score'].round().astype(int)\n",
    "\n",
    "deforestation_final.sort_values('score', ascending=False).head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DEFORESTATION MAPPING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load world shape data from geopandas\n",
    "world = gpd.read_file('maps/110m_cultural/ne_110m_admin_0_countries.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge with the world GeoDataFrame\n",
    "merged = world.merge(deforestation_final, how='left', left_on='ISO_A3', right_on='code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the map with filled shapes\n",
    "fig, ax = plt.subplots(1, 1, figsize=(20, 10))\n",
    "\n",
    "# Plot the countries with data\n",
    "merged.plot(column='score', cmap='OrRd', legend=False, ax=ax, missing_kwds={'color': 'lightgrey'})\n",
    "\n",
    "ax.axis('off')\n",
    "\n",
    "plt.title('World Map')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AIR POLLUTION CLEANING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "file_path = 'https://raw.githubusercontent.com/jipijipi/sql-database/main/sources/AQI%20and%20Lat%20Long%20of%20Countries.csv'\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert AQI Value to numeric, coerce errors to handle any non-numeric values\n",
    "df['AQI Value'] = pd.to_numeric(df['AQI Value'], errors='coerce')\n",
    "\n",
    "# Group by country and calculate the mean AQI value per country\n",
    "country_aqi = df.groupby('Country')['AQI Value'].mean().reset_index()\n",
    "\n",
    "# Min-Max normalization to scale AQI values between 1 and 10\n",
    "min_aqi = country_aqi['AQI Value'].min()\n",
    "max_aqi = country_aqi['AQI Value'].max()\n",
    "\n",
    "country_aqi['Pollution Score'] = 1 + 9 * (country_aqi['AQI Value'] - min_aqi) / (max_aqi - min_aqi)\n",
    "\n",
    "# Round and convert the Pollution Score to integers\n",
    "country_aqi['Rounded Pollution Score'] = country_aqi['Pollution Score'].round().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clean column names\n",
    "country_aqi.columns = country_aqi.columns.str.lower().str.replace(' ', '_')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get the 3-letter country code\n",
    "def get_country_code(country_name):\n",
    "    try:\n",
    "        return pycountry.countries.lookup(country_name).alpha_3\n",
    "    except LookupError:\n",
    "        return None\n",
    "\n",
    "# Add a new column with the 3-letter country code\n",
    "country_aqi['code'] = country_aqi['country'].apply(get_country_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AIR POLLUTION MAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge with the world GeoDataFrame\n",
    "merged = world.merge(country_aqi, how='left', left_on='ISO_A3', right_on='code')\n",
    "\n",
    "# Plot the map of air pollution scores\n",
    "fig, ax = plt.subplots(1, 1, figsize=(20, 10))\n",
    "\n",
    "# Plot the countries with data\n",
    "merged.plot(column='pollution_score', cmap='OrRd', legend='polution_score_rounded', ax=ax, missing_kwds={'color': 'lightgrey'})\n",
    "\n",
    "ax.axis('off')\n",
    "\n",
    "plt.title('Air pollution score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AIR POLLUTION LOAD IN SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "password = os.getenv(\"PASSWORD_A\")  # Retrieve the password from the .env file\n",
    "bd = \"business_trips\"  # Name of the database\n",
    "connection_string = f'mysql+pymysql://root:{password}@localhost/{bd}'  # Connection string\n",
    "engine = create_engine(connection_string)  # Create the SQLAlchemy engine\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv(\"/Users/annapisarek/Downloads/AQI_and_Country_Codes_clean.csv\")\n",
    "\n",
    "# Use the to_sql method with if_exists condition\n",
    "df.to_sql(\"air_pollution\", con=engine, if_exists='replace', index=False)\n",
    "\n",
    "# Close the connection if you created it explicitly (not needed with SQLAlchemy)\n",
    "# connection.close()  # Uncomment this if you used a raw connection\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
